{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Breed I: Keras - VGG16 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am following the fast.ai course, and this is my take on the Dog Breed competition based on that. In this an other notebooks I will try to get a good score on the Dog Breed competition (say top 50%).\n",
    "\n",
    "As a starting point, I will fine-tune the VGG16 model, for this, following the example of the dogs vs cat competition of the course. I already have saved the data as suggested. In the data folder I have train, validation and test folders.\n",
    "\n",
    "In this notebook I will:\n",
    "\n",
    "* Define the VGG-16 model using Keras, load the weights, and fine-tune it for this competition\n",
    "* Train the fine-tune version of the model\n",
    "* Produce a submission file for Kaggle\n",
    "\n",
    "All this code was added to the libraries utils and vgg16model. But I will leave it here too.\n",
    "\n",
    "But first let's us load some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/benjamin/anaconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 360 images belonging to 120 classes.\n",
      "Found 360 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import FileLink\n",
    "\n",
    "from importlib import reload\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "\n",
    "\n",
    "#import vgg16model; reload(vgg16model)\n",
    "#from vgg16model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is to avoid too many OOM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.layers import Dense, Flatten, Lambda, BatchNormalization, Dropout\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is just the VGG model definition. I have downloaded the weights for this previously, which I found at\n",
    "https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VGG16_PATH = 'models/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "\n",
    "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((1,1,3))\n",
    "def preproc(x):\n",
    "    x = x - vgg_mean\n",
    "    return x[:,:,:,::-1]\n",
    "\n",
    "def conv_block(model, layers, filters):\n",
    "    for i in range(layers):\n",
    "        model.add(Conv2D(filters, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "def fc_block(model, do):\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(do))\n",
    "\n",
    "def vgg16(do):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Lambda(preproc, input_shape=(224,224,3)))\n",
    "    \n",
    "    conv_block(model, 2, 64)\n",
    "    conv_block(model, 2, 128)\n",
    "    conv_block(model, 3, 256)\n",
    "    conv_block(model, 3, 512)\n",
    "    conv_block(model, 3, 512)\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    fc_block(model, do)\n",
    "    fc_block(model, do)\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    model.load_weights(VGG16_PATH)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def vgg16_dogbreed(do):\n",
    "    model = vgg16(do)\n",
    "\n",
    "    model.pop()\n",
    "    model.add(Dense(120, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = vgg16_dogbreed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the model with the weights loaded, we can fine tune it. Recall that for Dog Breed competition there are 120 categories so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 120)               491640    \n",
      "=================================================================\n",
      "Total params: 134,752,184\n",
      "Trainable params: 491,640\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[:-1]: layer.trainable=False\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we prepare the batches and train the model. In the first run, to verify that everything works, I will use the sample path, then I will subtitute it with the real path. Here is a function to obtain batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(path, gen=image.ImageDataGenerator(),\n",
    "              batch_size=4, shuffle=False):\n",
    "    '''Generate an iterator for batching, and the steps needed in each epoch'''\n",
    "    iterator = gen.flow_from_directory(path, target_size=(224,224),\n",
    "                                       batch_size=batch_size,\n",
    "                                       shuffle=shuffle)\n",
    "    steps_per_epoch = int(iterator.n/batch_size)\n",
    "    return iterator, steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path = 'data/sample/'\n",
    "path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9254 images belonging to 120 classes.\n",
      "Found 968 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batch, steps_per_epoch = get_batch(path + 'train', batch_size=batch_size, shuffle=True)\n",
    "valid_batch, validation_steps = get_batch(path + 'valid', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "145/144 [==============================] - 50s 347ms/step - loss: 3.0896 - acc: 0.3141 - val_loss: 1.5127 - val_acc: 0.5723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f13a85caf60>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_batch,steps_per_epoch, epochs=1,\n",
    "                   validation_data=valid_batch, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "145/144 [==============================] - 46s 317ms/step - loss: 1.1455 - acc: 0.6703 - val_loss: 1.1036 - val_acc: 0.6560\n",
      "Epoch 2/4\n",
      "145/144 [==============================] - 46s 316ms/step - loss: 0.7930 - acc: 0.7634 - val_loss: 0.9798 - val_acc: 0.6942\n",
      "Epoch 3/4\n",
      "145/144 [==============================] - 46s 316ms/step - loss: 0.6071 - acc: 0.8216 - val_loss: 0.9222 - val_acc: 0.7107\n",
      "Epoch 4/4\n",
      "145/144 [==============================] - 46s 316ms/step - loss: 0.4836 - acc: 0.8658 - val_loss: 0.8893 - val_acc: 0.7242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f13a8618a20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_batch,steps_per_epoch, epochs=4,\n",
    "                   validation_data=valid_batch, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('models/vgg16_fine_tuned_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now it is overfitting but still improving. I am going to use this as my starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to obtain the predictions is easy, but they are not real probabilities of each category, since the model, as far as I understand, tends to be overconfident. Which means we have to adjust the result for that. I designed the following function which tries to accomplish this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 360 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "_batch, _  = get_batch('data/sample/valid')\n",
    "DIC_CLASSES = _batch.class_indices\n",
    "INV_DIC = {str(v): k for k,v in DIC_CLASSES.items()}\n",
    "\n",
    "\n",
    "def adj(prediction, top_sum=0.98):\n",
    "    \"\"\"Adjust the output of a softmax so that the values are not too extreme\"\"\"\n",
    "    low_bar = 1-top_sum\n",
    "    adj_pred = np.copy(prediction)\n",
    "    old_top_sum = np.sum(adj_pred[adj_pred>=low_bar])\n",
    "    # We scale all the probabilities which are in a nice range, to add up to top_sum\n",
    "    adj_pred[adj_pred>=low_bar] = (top_sum/old_top_sum)*adj_pred[adj_pred>=low_bar] \n",
    "    # And set the rest so that they add up to low_bar.\n",
    "    adj_pred[adj_pred < low_bar] = low_bar/np.sum(adj_pred < low_bar)\n",
    "    return adj_pred\n",
    "\n",
    "\n",
    "test_path = 'data/test/'\n",
    "def prepare_submission(submission_file, model, top_sum=0.98):\n",
    "    \"\"\"Creates the file for the submission.\n",
    "    submission_file -> filename where to save the submission\n",
    "    model -> the Keras model which makes the prediction\n",
    "    top_sum -> to cap the predictions\n",
    "\n",
    "    returns a pandas DataFrame with the predictions.\"\"\"\n",
    "    test_batches, test_steps = get_batch(test_path, batch_size=64, shuffle=False)\n",
    "    names_of_pics = sorted(os.listdir(test_path+'unknown'))\n",
    "    predictions = model.predict_generator(test_batches, steps=test_steps)\n",
    "    test_df = pd.DataFrame()\n",
    "    test_df['id'] = [name[:-4] for name in names_of_pics]\n",
    "    test_df.set_index('id', inplace=True)\n",
    "    probs = np.array([adj(pred, top_sum) for pred in predictions])\n",
    "    for i in range(len(INV_DIC)):\n",
    "        test_df[INV_DIC[str(i)]] = np.transpose(probs)[i]\n",
    "    \n",
    "    test_df.to_csv(submission_file)\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('models/vgg16_fine_tuned_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_path = path + 'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10357 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_df = prepare_submission('submissions/new_submissions_1bisbis.csv', model, top_sum=0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>affenpinscher</th>\n",
       "      <th>afghan_hound</th>\n",
       "      <th>african_hunting_dog</th>\n",
       "      <th>airedale</th>\n",
       "      <th>american_staffordshire_terrier</th>\n",
       "      <th>appenzeller</th>\n",
       "      <th>australian_terrier</th>\n",
       "      <th>basenji</th>\n",
       "      <th>basset</th>\n",
       "      <th>beagle</th>\n",
       "      <th>...</th>\n",
       "      <th>toy_poodle</th>\n",
       "      <th>toy_terrier</th>\n",
       "      <th>vizsla</th>\n",
       "      <th>walker_hound</th>\n",
       "      <th>weimaraner</th>\n",
       "      <th>welsh_springer_spaniel</th>\n",
       "      <th>west_highland_white_terrier</th>\n",
       "      <th>whippet</th>\n",
       "      <th>wire-haired_fox_terrier</th>\n",
       "      <th>yorkshire_terrier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000621fb3cbb32d8935728e48679680e</th>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00102ee9d8eb90812350685311fe5890</th>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0012a730dfa437f5f3613fb75efcd4ce</th>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001510bc8570bbeee98c8d80c8a95ec1</th>\n",
       "      <td>0.054750</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001a5f3114548acdefa3d4da05474c2e</th>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  affenpinscher  afghan_hound  \\\n",
       "id                                                              \n",
       "000621fb3cbb32d8935728e48679680e       0.000168      0.000168   \n",
       "00102ee9d8eb90812350685311fe5890       0.000171      0.000171   \n",
       "0012a730dfa437f5f3613fb75efcd4ce       0.000174      0.000174   \n",
       "001510bc8570bbeee98c8d80c8a95ec1       0.054750      0.000180   \n",
       "001a5f3114548acdefa3d4da05474c2e       0.000174      0.000174   \n",
       "\n",
       "                                  african_hunting_dog  airedale  \\\n",
       "id                                                                \n",
       "000621fb3cbb32d8935728e48679680e             0.000168  0.000168   \n",
       "00102ee9d8eb90812350685311fe5890             0.000171  0.000171   \n",
       "0012a730dfa437f5f3613fb75efcd4ce             0.000174  0.000174   \n",
       "001510bc8570bbeee98c8d80c8a95ec1             0.000180  0.000180   \n",
       "001a5f3114548acdefa3d4da05474c2e             0.000174  0.000174   \n",
       "\n",
       "                                  american_staffordshire_terrier  appenzeller  \\\n",
       "id                                                                              \n",
       "000621fb3cbb32d8935728e48679680e                        0.000168     0.000168   \n",
       "00102ee9d8eb90812350685311fe5890                        0.000171     0.000171   \n",
       "0012a730dfa437f5f3613fb75efcd4ce                        0.000174     0.000174   \n",
       "001510bc8570bbeee98c8d80c8a95ec1                        0.000180     0.000180   \n",
       "001a5f3114548acdefa3d4da05474c2e                        0.000174     0.000174   \n",
       "\n",
       "                                  australian_terrier   basenji    basset  \\\n",
       "id                                                                         \n",
       "000621fb3cbb32d8935728e48679680e            0.000168  0.000168  0.000168   \n",
       "00102ee9d8eb90812350685311fe5890            0.000171  0.000171  0.000171   \n",
       "0012a730dfa437f5f3613fb75efcd4ce            0.000174  0.000174  0.000174   \n",
       "001510bc8570bbeee98c8d80c8a95ec1            0.000180  0.000180  0.000180   \n",
       "001a5f3114548acdefa3d4da05474c2e            0.000174  0.000174  0.000174   \n",
       "\n",
       "                                    beagle        ...          toy_poodle  \\\n",
       "id                                                ...                       \n",
       "000621fb3cbb32d8935728e48679680e  0.000168        ...            0.000168   \n",
       "00102ee9d8eb90812350685311fe5890  0.000171        ...            0.000171   \n",
       "0012a730dfa437f5f3613fb75efcd4ce  0.000174        ...            0.000174   \n",
       "001510bc8570bbeee98c8d80c8a95ec1  0.000180        ...            0.000180   \n",
       "001a5f3114548acdefa3d4da05474c2e  0.000174        ...            0.000174   \n",
       "\n",
       "                                  toy_terrier    vizsla  walker_hound  \\\n",
       "id                                                                      \n",
       "000621fb3cbb32d8935728e48679680e     0.000168  0.000168      0.000168   \n",
       "00102ee9d8eb90812350685311fe5890     0.000171  0.000171      0.000171   \n",
       "0012a730dfa437f5f3613fb75efcd4ce     0.000174  0.000174      0.000174   \n",
       "001510bc8570bbeee98c8d80c8a95ec1     0.000180  0.000180      0.000180   \n",
       "001a5f3114548acdefa3d4da05474c2e     0.000174  0.000174      0.000174   \n",
       "\n",
       "                                  weimaraner  welsh_springer_spaniel  \\\n",
       "id                                                                     \n",
       "000621fb3cbb32d8935728e48679680e    0.000168                0.000168   \n",
       "00102ee9d8eb90812350685311fe5890    0.000171                0.000171   \n",
       "0012a730dfa437f5f3613fb75efcd4ce    0.000174                0.000174   \n",
       "001510bc8570bbeee98c8d80c8a95ec1    0.000180                0.000180   \n",
       "001a5f3114548acdefa3d4da05474c2e    0.000174                0.000174   \n",
       "\n",
       "                                  west_highland_white_terrier   whippet  \\\n",
       "id                                                                        \n",
       "000621fb3cbb32d8935728e48679680e                     0.000168  0.000168   \n",
       "00102ee9d8eb90812350685311fe5890                     0.000171  0.000171   \n",
       "0012a730dfa437f5f3613fb75efcd4ce                     0.000174  0.000174   \n",
       "001510bc8570bbeee98c8d80c8a95ec1                     0.000180  0.000180   \n",
       "001a5f3114548acdefa3d4da05474c2e                     0.000174  0.000174   \n",
       "\n",
       "                                  wire-haired_fox_terrier  yorkshire_terrier  \n",
       "id                                                                            \n",
       "000621fb3cbb32d8935728e48679680e                 0.000168           0.000168  \n",
       "00102ee9d8eb90812350685311fe5890                 0.000171           0.000171  \n",
       "0012a730dfa437f5f3613fb75efcd4ce                 0.000174           0.000174  \n",
       "001510bc8570bbeee98c8d80c8a95ec1                 0.000180           0.000180  \n",
       "001a5f3114548acdefa3d4da05474c2e                 0.000174           0.000174  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submissions/new_submissions_1bisbis.csv' target='_blank'>submissions/new_submissions_1bisbis.csv</a><br>"
      ],
      "text/plain": [
       "/media/benjamin/Baul/Proyectos/ml_experiments/dogbreed/submissions/new_submissions_1bisbis.csv"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink('submissions/new_submissions_1bisbis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This got a score of 1.13167"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10357 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py:12: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "test_df = prepare_submission('submissions/new_submissions_1bis2bis.csv', model, top_sum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>affenpinscher</th>\n",
       "      <th>afghan_hound</th>\n",
       "      <th>african_hunting_dog</th>\n",
       "      <th>airedale</th>\n",
       "      <th>american_staffordshire_terrier</th>\n",
       "      <th>appenzeller</th>\n",
       "      <th>australian_terrier</th>\n",
       "      <th>basenji</th>\n",
       "      <th>basset</th>\n",
       "      <th>beagle</th>\n",
       "      <th>...</th>\n",
       "      <th>toy_poodle</th>\n",
       "      <th>toy_terrier</th>\n",
       "      <th>vizsla</th>\n",
       "      <th>walker_hound</th>\n",
       "      <th>weimaraner</th>\n",
       "      <th>welsh_springer_spaniel</th>\n",
       "      <th>west_highland_white_terrier</th>\n",
       "      <th>whippet</th>\n",
       "      <th>wire-haired_fox_terrier</th>\n",
       "      <th>yorkshire_terrier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000621fb3cbb32d8935728e48679680e</th>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00102ee9d8eb90812350685311fe5890</th>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0012a730dfa437f5f3613fb75efcd4ce</th>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001510bc8570bbeee98c8d80c8a95ec1</th>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001a5f3114548acdefa3d4da05474c2e</th>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.001695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  affenpinscher  afghan_hound  \\\n",
       "id                                                              \n",
       "000621fb3cbb32d8935728e48679680e       0.001681      0.001681   \n",
       "00102ee9d8eb90812350685311fe5890       0.001681      0.001681   \n",
       "0012a730dfa437f5f3613fb75efcd4ce       0.001681      0.001681   \n",
       "001510bc8570bbeee98c8d80c8a95ec1       0.001681      0.001681   \n",
       "001a5f3114548acdefa3d4da05474c2e       0.001695      0.001695   \n",
       "\n",
       "                                  african_hunting_dog  airedale  \\\n",
       "id                                                                \n",
       "000621fb3cbb32d8935728e48679680e             0.001681  0.001681   \n",
       "00102ee9d8eb90812350685311fe5890             0.001681  0.001681   \n",
       "0012a730dfa437f5f3613fb75efcd4ce             0.001681  0.001681   \n",
       "001510bc8570bbeee98c8d80c8a95ec1             0.001681  0.001681   \n",
       "001a5f3114548acdefa3d4da05474c2e             0.001695  0.001695   \n",
       "\n",
       "                                  american_staffordshire_terrier  appenzeller  \\\n",
       "id                                                                              \n",
       "000621fb3cbb32d8935728e48679680e                        0.001681     0.001681   \n",
       "00102ee9d8eb90812350685311fe5890                        0.001681     0.001681   \n",
       "0012a730dfa437f5f3613fb75efcd4ce                        0.001681     0.001681   \n",
       "001510bc8570bbeee98c8d80c8a95ec1                        0.001681     0.001681   \n",
       "001a5f3114548acdefa3d4da05474c2e                        0.001695     0.001695   \n",
       "\n",
       "                                  australian_terrier   basenji    basset  \\\n",
       "id                                                                         \n",
       "000621fb3cbb32d8935728e48679680e            0.001681  0.001681  0.001681   \n",
       "00102ee9d8eb90812350685311fe5890            0.001681  0.001681  0.001681   \n",
       "0012a730dfa437f5f3613fb75efcd4ce            0.001681  0.001681  0.001681   \n",
       "001510bc8570bbeee98c8d80c8a95ec1            0.001681  0.001681  0.001681   \n",
       "001a5f3114548acdefa3d4da05474c2e            0.001695  0.001695  0.001695   \n",
       "\n",
       "                                    beagle        ...          toy_poodle  \\\n",
       "id                                                ...                       \n",
       "000621fb3cbb32d8935728e48679680e  0.001681        ...            0.001681   \n",
       "00102ee9d8eb90812350685311fe5890  0.001681        ...            0.001681   \n",
       "0012a730dfa437f5f3613fb75efcd4ce  0.001681        ...            0.001681   \n",
       "001510bc8570bbeee98c8d80c8a95ec1  0.001681        ...            0.001681   \n",
       "001a5f3114548acdefa3d4da05474c2e  0.001695        ...            0.001695   \n",
       "\n",
       "                                  toy_terrier    vizsla  walker_hound  \\\n",
       "id                                                                      \n",
       "000621fb3cbb32d8935728e48679680e     0.001681  0.001681      0.001681   \n",
       "00102ee9d8eb90812350685311fe5890     0.001681  0.001681      0.001681   \n",
       "0012a730dfa437f5f3613fb75efcd4ce     0.001681  0.001681      0.001681   \n",
       "001510bc8570bbeee98c8d80c8a95ec1     0.001681  0.001681      0.001681   \n",
       "001a5f3114548acdefa3d4da05474c2e     0.001695  0.001695      0.001695   \n",
       "\n",
       "                                  weimaraner  welsh_springer_spaniel  \\\n",
       "id                                                                     \n",
       "000621fb3cbb32d8935728e48679680e    0.001681                0.001681   \n",
       "00102ee9d8eb90812350685311fe5890    0.001681                0.001681   \n",
       "0012a730dfa437f5f3613fb75efcd4ce    0.001681                0.001681   \n",
       "001510bc8570bbeee98c8d80c8a95ec1    0.001681                0.001681   \n",
       "001a5f3114548acdefa3d4da05474c2e    0.001695                0.001695   \n",
       "\n",
       "                                  west_highland_white_terrier   whippet  \\\n",
       "id                                                                        \n",
       "000621fb3cbb32d8935728e48679680e                     0.001681  0.001681   \n",
       "00102ee9d8eb90812350685311fe5890                     0.001681  0.001681   \n",
       "0012a730dfa437f5f3613fb75efcd4ce                     0.001681  0.001681   \n",
       "001510bc8570bbeee98c8d80c8a95ec1                     0.001681  0.001681   \n",
       "001a5f3114548acdefa3d4da05474c2e                     0.001695  0.001695   \n",
       "\n",
       "                                  wire-haired_fox_terrier  yorkshire_terrier  \n",
       "id                                                                            \n",
       "000621fb3cbb32d8935728e48679680e                 0.001681           0.001681  \n",
       "00102ee9d8eb90812350685311fe5890                 0.001681           0.001681  \n",
       "0012a730dfa437f5f3613fb75efcd4ce                 0.001681           0.001681  \n",
       "001510bc8570bbeee98c8d80c8a95ec1                 0.001681           0.001681  \n",
       "001a5f3114548acdefa3d4da05474c2e                 0.001695           0.001695  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submissions/new_submissions_1bis2bis.csv' target='_blank'>submissions/new_submissions_1bis2bis.csv</a><br>"
      ],
      "text/plain": [
       "/media/benjamin/Baul/Proyectos/ml_experiments/dogbreed/submissions/new_submissions_1bis2bis.csv"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink('submissions/new_submissions_1bis2bis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This got a worse score of 2.63477"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
